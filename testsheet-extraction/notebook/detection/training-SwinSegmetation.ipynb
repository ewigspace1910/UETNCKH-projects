{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOM1oXXqo6czySkUitMUDi/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ENV"],"metadata":{"id":"LBx5TaOblGDL"}},{"cell_type":"code","source":["!apt install python3.8\n","!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n","!update-alternatives --set python3 /usr/bin/python3.8\n","!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n","!python get-pip.py\n","!pip --version\n","!python3 -m pip install setuptools==59.5.0\n","!pip install virtualenv\n","!python3 -m virtualenv venv\n"],"metadata":{"id":"VyYf0La2lWnV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !source /content/venv/bin/activate; pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html\n","!source venv/bin/activate; pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"],"metadata":{"id":"XNO6_i2AmAle"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/facebookresearch/detectron2.git\n","%cd detectron2\n","!source /content/venv/bin/activate; pip install -e ."],"metadata":{"id":"-2q1BX1one0K"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKP73Gv7lAhK"},"outputs":[],"source":["%cd ..\n","!git clone https://github.com/ayanban011/SwinDocSegmenter.git\n","%cd SwinDocSegmenter\n"]},{"cell_type":"code","source":["%cd /content/SwinDocSegmenter/"],"metadata":{"id":"1wcCaGgXpwmc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!source /content/venv/bin/activate; pip install -r requirements.txt\n"],"metadata":{"id":"ymQvk-5_pmlP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd maskdino/modeling/pixel_decoder/ops\n","!source /content/venv/bin/activate; sh make.sh"],"metadata":{"id":"Wu-8dY8HprOE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DATA"],"metadata":{"id":"WY2LFD-hlDv0"}},{"cell_type":"code","source":["!pip install gdown"],"metadata":{"id":"kH3zH9G6lEt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown -O publaynet.zip --id 1qvvj4QYWlXZHYAgahEYUfH2UUmbX6u_q\n","!unzip publaynet.zip"],"metadata":{"id":"tDDx2ls_sGLm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!export DETECTRON2_DATASETS=/content/content"],"metadata":{"id":"razTRmPwuco_","executionInfo":{"status":"ok","timestamp":1684377758573,"user_tz":-420,"elapsed":344,"user":{"displayName":"19021208 Nguyễn Đức Anh","userId":"08254892338316082189"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["!source /content/venv/bin/activate;pip install git+https://github.com/cocodataset/panopticapi.git"],"metadata":{"id":"1WH8UVPdui8C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!source /content/venv/bin/activate; python /content/SwinDocSegmenter/datasets/prepare_coco_semantic_annos_from_panoptic_annos.py"],"metadata":{"id":"qXm_-RURveci"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TRAINING"],"metadata":{"id":"i5f899kulE0v"}},{"cell_type":"code","source":["%cd /content/SwinDocSegmenter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KwhMWfK9tjDJ","executionInfo":{"status":"ok","timestamp":1684377339031,"user_tz":-420,"elapsed":2,"user":{"displayName":"19021208 Nguyễn Đức Anh","userId":"08254892338316082189"}},"outputId":"76b28a85-fa70-4db6-cb6f-8cf93673cb86"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/SwinDocSegmenter\n"]}]},{"cell_type":"code","source":["!cp /content/SwinDocSegmenter/configs/coco/instance-segmentation/Base-COCO-InstanceSegmentation.yaml /content/base.yaml"],"metadata":{"id":"2WJlMvHWrMQ2","executionInfo":{"status":"ok","timestamp":1684377349284,"user_tz":-420,"elapsed":318,"user":{"displayName":"19021208 Nguyễn Đức Anh","userId":"08254892338316082189"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["#@title config\n","cfg = \"\"\"\n","_BASE_: /content/base.yaml\n","MODEL:\n","  META_ARCHITECTURE: \"MaskDINO\"\n","  SEM_SEG_HEAD:\n","    NAME: \"MaskDINOHead\"\n","    IGNORE_VALUE: 255\n","    NUM_CLASSES: 11\n","    LOSS_WEIGHT: 1.0\n","    CONVS_DIM: 256\n","    MASK_DIM: 256\n","    NORM: \"GN\"\n","    # pixel decoder\n","    PIXEL_DECODER_NAME: \"MaskDINOEncoder\"\n","    DIM_FEEDFORWARD: 2048\n","    NUM_FEATURE_LEVELS: 3\n","    TOTAL_NUM_FEATURE_LEVELS: 4\n","    IN_FEATURES: [\"res2\", \"res3\", \"res4\", \"res5\"]\n","    DEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES: [\"res2\",\"res3\", \"res4\", \"res5\"]\n","    COMMON_STRIDE: 4\n","    TRANSFORMER_ENC_LAYERS: 6\n","    FEATURE_ORDER: \"low2high\"\n","  MaskDINO:\n","    TRANSFORMER_DECODER_NAME: \"MaskDINODecoder\"\n","    DEEP_SUPERVISION: True\n","    NO_OBJECT_WEIGHT: 0.1\n","    CLASS_WEIGHT: 4.0\n","    MASK_WEIGHT: 5.0\n","    DICE_WEIGHT: 5.0\n","    BOX_WEIGHT: 5.0\n","    GIOU_WEIGHT: 2.0\n","    HIDDEN_DIM: 256\n","    NUM_OBJECT_QUERIES: 300\n","    NHEADS: 8\n","    DROPOUT: 0.0\n","    DIM_FEEDFORWARD: 1024\n","    ENC_LAYERS: 0\n","    PRE_NORM: False\n","    ENFORCE_INPUT_PROJ: False\n","    SIZE_DIVISIBILITY: 32\n","    DEC_LAYERS: 9  # 9+1, 9 decoder layers, add one for the loss on learnable query\n","    TRAIN_NUM_POINTS: 12544\n","    OVERSAMPLE_RATIO: 3.0\n","    IMPORTANCE_SAMPLE_RATIO: 0.75\n","    EVAL_FLAG: 1\n","    INITIAL_PRED: True\n","    TWO_STAGE: True\n","    DN: \"seg\"\n","    DN_NUM: 100\n","    INITIALIZE_BOX_TYPE: 'no'\n","    TEST:\n","      SEMANTIC_ON: False\n","      INSTANCE_ON: True\n","      PANOPTIC_ON: False\n","      OVERLAP_THRESHOLD: 0.8\n","      OBJECT_MASK_THRESHOLD: 0.25\n","DATASETS:\n","  TRAIN: (\"doc_train\",)\n","  TEST: (\"doc_val\",)\n","SOLVER:\n","  AMP:\n","    ENABLED: True\n","DATALOADER:\n","  NUM_WORKERS: 2\n","TEST:\n","  EVAL_PERIOD: 5000\n","#  EVAL_FLAG: 1\n","OUTPUT_DIR: \"/content/output_doclay_comp_Res\"\n","\"\"\"\n","with open(\"/content/cfg.yaml\", \"w\") as f:\n","    f.write(cfg)\n"],"metadata":{"cellView":"form","id":"9XpfOB-0qmK6","executionInfo":{"status":"ok","timestamp":1684377354689,"user_tz":-420,"elapsed":310,"user":{"displayName":"19021208 Nguyễn Đức Anh","userId":"08254892338316082189"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["!gdown -O /content/weight.pth --id 1DCxG2MCza_z-yB3bLcaVvVR4Jik00Ecq"],"metadata":{"id":"J7_sOq96sy9F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!source /content/venv/bin/activate; python train_net.py --num-gpus 1 \\\n","    --config-file /content/cfg.yaml \\\n","    SOLVER.IMS_PER_BATCH 4 SOLVER.BASE_LR 0.000025 MODEL.NUM_CLASSES 8 \\\n","    SOLVER.STEPS: 3000 4000  SOLVER.MAX_ITER: 16000 \\\n","    DATASETS.TRAIN \"/content/content/coco/train\" \\\n","    DATASETS.TEST \"/content/content/coco/val\" \\\n","    MODEL.WEIGHTS \"/content/weight.pth\""],"metadata":{"id":"6JoFty6UqP9N"},"execution_count":null,"outputs":[]}]}