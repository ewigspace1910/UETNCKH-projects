{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNdp/AQ8WkAZPpd7wnF6Va5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IxlzOdqNQKae"},"outputs":[],"source":["!apt install python3.8\n","!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n","!update-alternatives --set python3 /usr/bin/python3.8\n","!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n","!python get-pip.py\n","!pip --version\n","!python3 -m pip install setuptools==59.5.0\n","# !pip install virtualenv\n","# !python3 -m virtualenv venv\n"]},{"cell_type":"code","source":["!git clone https://github.com/PaddlePaddle/PaddleOCR\n","%cd PaddleOCR\n","!pip3 install -r requirements.txt"],"metadata":{"id":"ovQv_0QUTGwX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DATA"],"metadata":{"id":"JMG3GY7iVmHb"}},{"cell_type":"code","source":["!pip install gdown\n","!gdown -O crohme.zip  --id 13vjxGYrFCuYnwgDIUqkxsNGKk__D_sOM"],"metadata":{"id":"Njcoa-PnVm_u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip crohme.zip"],"metadata":{"id":"siXNmbUNV_P4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TRAINING"],"metadata":{"id":"dYqg41PRRP8l"}},{"cell_type":"code","source":["#@title cfg\n","cfg = \"\"\"\n","Global:\n","  use_gpu: True\n","  epoch_num: 240\n","  log_smooth_window: 20\n","  print_batch_step: 10\n","  save_model_dir: ./output/rec/can/\n","  save_epoch_step: 1\n","  # evaluation is run every 1105 iterations (1 epoch)(batch_size = 8)\n","  eval_batch_step: [0, 1105]\n","  cal_metric_during_train: True\n","  pretrained_model:\n","  checkpoints:\n","  save_inference_dir:\n","  use_visualdl: False\n","  infer_img: doc/datasets/crohme_demo/hme_00.jpg\n","  # for data or label process\n","  character_dict_path: ppocr/utils/dict/latex_symbol_dict.txt\n","  max_text_length: 36\n","  infer_mode: False\n","  use_space_char: False\n","  save_res_path: ./output/rec/predicts_can.txt\n","\n","Optimizer:\n","  name: Momentum\n","  momentum: 0.9\n","  clip_norm_global: 100.0\n","  lr:\n","    name: TwoStepCosine\n","    learning_rate: 0.01\n","    warmup_epoch: 1\n","  weight_decay: 0.0001\n","\n","Architecture:\n","  model_type: rec\n","  algorithm: CAN\n","  in_channels: 1\n","  Transform:\n","  Backbone:\n","    name: DenseNet \n","    growthRate: 24\n","    reduction: 0.5\n","    bottleneck: True\n","    use_dropout: True\n","    input_channel: 1 \n","  Head:\n","    name: CANHead\n","    in_channel: 684\n","    out_channel: 111\n","    max_text_length: 36\n","    ratio: 16\n","    attdecoder:\n","      is_train: True\n","      input_size: 256\n","      hidden_size: 256\n","      encoder_out_channel: 684\n","      dropout: True\n","      dropout_ratio: 0.5\n","      word_num: 111\n","      counting_decoder_out_channel: 111\n","      attention:\n","        attention_dim: 512\n","        word_conv_kernel: 1\n","   \n","Loss:\n","  name: CANLoss\n","\n","PostProcess:\n","  name: CANLabelDecode\n","\n","Metric:\n","  name: CANMetric\n","  main_indicator: exp_rate\n","\n","Train:\n","  dataset:\n","    name: SimpleDataSet\n","    data_dir: ./train_data/CROHME/training/images/\n","    label_file_list: [\"./train_data/CROHME/training/labels.txt\"]\n","    transforms:\n","      - DecodeImage:\n","          channel_first: False\n","      - NormalizeImage:\n","          mean: [0,0,0]\n","          std: [1,1,1]\n","          order: 'hwc'\n","      - GrayImageChannelFormat: \n","          inverse: True\n","      - CANLabelEncode:\n","          lower: False\n","      - KeepKeys:\n","          keep_keys: ['image', 'label']\n","  loader:\n","    shuffle: True\n","    batch_size_per_card: 8\n","    drop_last: False\n","    num_workers: 4\n","    collate_fn: DyMaskCollator\n","\n","Eval:\n","  dataset:\n","    name: SimpleDataSet\n","    data_dir: ./train_data/CROHME/evaluation/images/\n","    label_file_list: [\"./train_data/CROHME/evaluation/labels.txt\"]\n","    transforms: \n","      - DecodeImage:\n","          channel_first: False\n","      - NormalizeImage:\n","          mean: [0,0,0]\n","          std: [1,1,1]\n","          order: 'hwc'\n","      - GrayImageChannelFormat:\n","          inverse: True\n","      - CANLabelEncode:\n","          lower: False\n","      - KeepKeys:\n","          keep_keys: ['image', 'label']\n","  loader:\n","    shuffle: False\n","    drop_last: False\n","    batch_size_per_card: 1\n","    num_workers: 4\n","    collate_fn: DyMaskCollator\n","\n","\"\"\"\n","with open(\"/content/cfg.yaml\", \"w\") as f:\n","    f.write(cfg)"],"metadata":{"cellView":"form","id":"I8Mu-WjJT4IU","executionInfo":{"status":"ok","timestamp":1684722948650,"user_tz":-420,"elapsed":6,"user":{"displayName":"19021208 Nguyễn Đức Anh","userId":"08254892338316082189"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!python3 tools/train.py -c content/cfg.yaml"],"metadata":{"id":"vcewAEZERSM5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EVAL"],"metadata":{"id":"pzH7yjphRSWu"}},{"cell_type":"code","source":[],"metadata":{"id":"vz0vPHwKRTUI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The configuration file used for prediction must match the training\n","!python3 tools/infer_rec.py -c configs/rec/rec_d28_can.yml \\\n"," -o Architecture.Head.attdecoder.is_train=False  \\\n"," Global.infer_img='./doc/crohme_demo/hme_00.jpg' \\\n"," Global.pretrained_model=./rec_d28_can_train/best_accuracy.pdparams"],"metadata":{"id":"e5E__W2NTpAJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python3 tools/infer/predict_rec.py \\\n","--image_dir=\"./doc/datasets/crohme_demo/hme_00.jpg\"  \\\n","--rec_algorithm=\"CAN\" --rec_batch_num=1  \\\n","--rec_model_dir=\"./inference/rec_d28_can/\" \\\n","--rec_char_dict_path=\"./ppocr/utils/dict/latex_symbol_dict.txt\"\n","\n","# If you need to predict on a picture with black characters on a white background, please set: -- rec_ image_ inverse=False"],"metadata":{"id":"v8ZncFWeU4V0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MISC"],"metadata":{"id":"X-vTOhSxRT4b"}},{"cell_type":"code","source":[],"metadata":{"id":"A_NsGMH_RU2H"},"execution_count":null,"outputs":[]}]}