{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd9248e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import AsyncOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Path to Grammatical Range and Accuracy JSONL file\n",
    "file_path = '/home/ducanh/nvidia-llm-pipeline/unslot/ft_qwen/outputs/gap.json'\n",
    "gra_data = []\n",
    "\n",
    "# Open and read the JSONL file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Parse each line as JSON\n",
    "        gra_data.append(json.loads(line.strip()))\n",
    "\n",
    "# Path to Lexical Resource JSONL file\n",
    "file_path = 'ielts_speech_ft_preds/peft_prediction_lr_llama_070525.jsonl'\n",
    "lr_data = []\n",
    "\n",
    "# Open and read the JSONL file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Parse each line as JSON\n",
    "        lr_data.append(json.loads(line.strip()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3bec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "def get_linest(y_values_poly, x_values_poly):\n",
    "    # Convert to NumPy arrays and reshape for sklearn\n",
    "    X_poly = np.array(x_values_poly).reshape(-1, 1)\n",
    "    Y_poly = np.array(y_values_poly)\n",
    "\n",
    "    # Define the polynomial degree (degree 2 for quadratic fit)\n",
    "    degree = 1\n",
    "\n",
    "    # Transform the data to include polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_poly_transformed = poly.fit_transform(X_poly)\n",
    "\n",
    "    # Fit the polynomial regression model\n",
    "    model_poly = LinearRegression()\n",
    "    model_poly.fit(X_poly_transformed, Y_poly)\n",
    "\n",
    "    return model_poly.coef_, model_poly.intercept_\n",
    "\n",
    "def get_mapping(coefs, intercept, x_values):\n",
    "    return [max(1,min(9,round(intercept+sum([coef*x_val**degree for degree, coef in enumerate(coefs)])))) for x_val in x_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e057c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_gra_score_pred(input_text):\n",
    "    client = AsyncOpenAI()\n",
    "    json_schema_gra = {\n",
    "    \"name\": \"grammatical_range_and_accuracy_score\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "        \"grammatical_range_and_accuracy\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"The overall score representing the grammatical range and accuracy.\"\n",
    "        },\n",
    "        },\n",
    "        \"required\": [\n",
    "        \"grammatical_range_and_accuracy\",\n",
    "        ],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "    }\n",
    "    response_score = await client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\":\"system\", \"content\":\"Convert the score into JSON.\"},{\"role\":\"user\", \"content\":input_text}],\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "        max_tokens=4096,\n",
    "        response_format={\"type\": \"json_schema\", \"json_schema\":json_schema_gra}\n",
    "    )\n",
    "    return json.loads(response_score.choices[0].message.content)['grammatical_range_and_accuracy']\n",
    "\n",
    "async def get_lr_score_pred(input_text):\n",
    "    client = AsyncOpenAI()\n",
    "    json_schema_lr = {\n",
    "    \"name\": \"lexical_resource_score\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "        \"lexical_resource\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"The overall score representing the lexical resource.\"\n",
    "        },\n",
    "        },\n",
    "        \"required\": [\n",
    "        \"lexical_resource\",\n",
    "        ],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "    }\n",
    "    response_score = await client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\":\"system\", \"content\":\"Convert the score into JSON.\"},{\"role\":\"user\", \"content\":input_text}],\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "        max_tokens=4096,\n",
    "        response_format={\"type\": \"json_schema\", \"json_schema\":json_schema_lr}\n",
    "    )\n",
    "    return json.loads(response_score.choices[0].message.content)['lexical_resource']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d723697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the JSONL file has 'input', 'label', and 'prediction' fields\n",
    "gra_input = [gra_item['input'] for gra_item in gra_data]\n",
    "gra_target = [float(gra_item['label'].split(\" \")[-1]) for gra_item in gra_data]\n",
    "# Getting score from prediction string using OpenAI, use own prediction extraction method if available\n",
    "gra_pred_tasks = [get_gra_score_pred(gra_item['prediction']) for gra_item in gra_data]\n",
    "gra_preds = await asyncio.gather(*gra_pred_tasks)\n",
    "# Prediction score extraction end\n",
    "gra_linest = get_linest(gra_target, gra_preds)\n",
    "\n",
    "lr_input = [lr_item['input'] for lr_item in lr_data]\n",
    "lr_target = [float(lr_item['label'].split(\" \")[-1]) for lr_item in lr_data]\n",
    "# Getting score from prediction string using OpenAI, use own prediction extraction method if available\n",
    "lr_pred_tasks = [get_lr_score_pred(lr_item['prediction']) for lr_item in lr_data]\n",
    "lr_preds = await asyncio.gather(*lr_pred_tasks)\n",
    "# Prediction score extraction end\n",
    "lr_linest = get_linest(lr_target, lr_preds)\n",
    "\n",
    "gra_df = pd.DataFrame({\n",
    "    \"input\": gra_input,\n",
    "    \"target\": gra_target,\n",
    "    \"pred\": gra_preds,\n",
    "    \"acc\":[item_target-1<=item<=item_target+1 for item_target,item in zip(gra_target,gra_preds)],\n",
    "    \"pred_mapped\": get_mapping(gra_linest[0], gra_linest[1], gra_preds),\n",
    "    \"acc_mapped\": [item_target-1<=item<=item_target+1 for item_target,item in zip(gra_target,get_mapping(gra_linest[0], gra_linest[1], gra_preds))],\n",
    "})\n",
    "\n",
    "lr_df = pd.DataFrame({\n",
    "    \"input\": lr_input,\n",
    "    \"target\": lr_target,\n",
    "    \"pred\": lr_preds,\n",
    "    \"acc\":[item_target-1<=item<=item_target+1 for item_target,item in zip(lr_target,lr_preds)],\n",
    "    \"pred_mapped\": get_mapping(lr_linest[0], lr_linest[1], lr_preds),\n",
    "    \"acc_mapped\": [item_target-1<=item<=item_target+1 for item_target,item in zip(lr_target,get_mapping(lr_linest[0], lr_linest[1], lr_preds))],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammatical Range and Accuracy mapping coef and intercept:\n",
      "Coefficients: [0.         0.72480106]\n",
      "Intercept: 3.217506631299734\n",
      "\n",
      "Lexical Resource mapping coef and intercept:\n",
      "Coefficients: [0.        1.0825701]\n",
      "Intercept: 2.782020572072704\n"
     ]
    }
   ],
   "source": [
    "print(f\"Grammatical Range and Accuracy mapping coef and intercept:\\nCoefficients: {gra_linest[0]}\\nIntercept: {gra_linest[1]}\")\n",
    "print()\n",
    "print(f\"Lexical Resource mapping coef and intercept:\\nCoefficients: {lr_linest[0]}\\nIntercept: {lr_linest[1]}\")\n",
    "# Counting accurate predictions/total predictions\n",
    "print(f\"Grammatical Range and Accuracy rubric accuracy:\\nUnmapped: {round(gra_df['acc'].sum()/gra_df['acc'].count()*100,2)}%\\nMapped: {round(gra_df['acc_mapped'].sum()/gra_df['acc_mapped'].count()*100,2)}%\")\n",
    "print()\n",
    "print(f\"Lexical Resource rubric accuracy:\\nUnmapped: {round(lr_df['acc'].sum()/lr_df['acc'].count()*100,2)}%\\nMapped: {round(lr_df['acc_mapped'].sum()/lr_df['acc_mapped'].count()*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b73ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammatical Range and Accuracy rubric accuracy:\n",
      "Unmapped: 31.48%\n",
      "Mapped: 64.81%\n",
      "\n",
      "Lexical Resource rubric accuracy:\n",
      "Unmapped: 12.96%\n",
      "Mapped: 66.67%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the DFs as excel\n",
    "gra_df.to_excel(\"ielts_speech_ft_preds/GRA evaluation result.xlsx\")\n",
    "lr_df.to_excel(\"ielts_speech_ft_preds/LR evaluation result.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
